{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AD9N/clima-DL/blob/dev-model-JosafatZM/Copia_Final_de_TL_P1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Práctica #1: Modelo para predicción de lluvia**\n",
        "\n",
        "*Centro Universitario de Ciencias Exactas e Ingenierías*\n",
        "\n",
        "*División de Tecnologías para la Integración Ciber-Humana*\n",
        "\n",
        "*Ingeniería Biomédica*\n",
        "\n",
        "<br>\n",
        "\n",
        "*Mtra. Sofía Alejandra Aguilar Valdez*\n",
        "\n",
        "2 de septiembre de 2022"
      ],
      "metadata": {
        "id": "nVx-kou4pjFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Información del equipo**\n",
        "\n",
        "```NOMBRES:```\n",
        "José Adán Avalos Cabrera, Josafat Zamora Muñoz \n",
        ", Agustín Villareal Carrillo.\n",
        "\n",
        "\n",
        "```CÓDIGOS:``` \n",
        "220790407 ,221340492, 219747379.\n",
        "\n",
        "```LINK REPOSITORIO:```\n",
        "https://github.com/AD9N/clima-DL.git\n",
        "\n"
      ],
      "metadata": {
        "id": "dQNzG9Wm4ZQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Contenido**\n",
        "\n",
        "\n",
        "\n",
        "1.   Resumen\n",
        "2.   Marco teórico\n",
        "3.   Objetivos\n",
        "4.   Materiales y métodos\n",
        "5.   Resultados\n",
        "6.   Discusión\n",
        "7.   Conclusiones\n",
        "8.   Referencias\n",
        "\n"
      ],
      "metadata": {
        "id": "QQ_tQMMJpude"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Resumen**\n",
        "Las Artificial Neural Networks (o Neural Networks) se constituyen mediante capas de neuronas interconectadas. Los datos ingresan por medio de la capa de entrada pasan a través de la capa oculta, la cual puede estar construida por varias capas, y salen por la capa de salida. Debido a su construcción las ANN presentan un gran número de características semejantes a las del cerebro.\n",
        "Pytorch es un framework para machine learning de código abierto implementado por Meta. Este framework tiene varios módulos interesantes para el desarrollo de redes neuronales.\n",
        "Para poder construir una red neuronal se empleó de esta tecnología a partir de la documentación establecida, así mismo con el entorno de Colab Pro para más rendimiento en la memoria gráfica\n"
      ],
      "metadata": {
        "id": "anvzyOk06GH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Marco teórico**\n",
        "#**Neural Network Model para predicción de precipitaciones:**\n",
        "En este cuaderno de colaboratory construimos un modelo de predicción para conocer las probabilidades de lluvia basándonos en los recursos obtenidos de la base de datos del Seattle-Tacoma International Airport.\n",
        "Para familiarizarnos con algunos conceptos con los que estaremos trabajando definiremos de manera concisa algunos conceptos que son indispensables conocer para este trabajo como lo son las Artificial Neural Networks el Underfitting y el Overfitting que son conceptos y herramientas que estaremos utilizando a lo largo de esta práctica.\n",
        "\n",
        "#**Artificial Neural Network:**\n",
        "Inspiradas en la sofisticada arquitectura del cerebro humano donde miles de millones de neuronas interconectadas procesan información. Las Artificial Neural Networks (o Neural Networks) se constituyen mediante capas de neuronas interconectadas. Los datos ingresan por medio de la capa de entrada pasan a través de la capa oculta, la cual puede estar construida por varias capas, y salen por la capa de salida.\n",
        "Debido a su construcción las ANN presentan un gran número de características semejantes a las del cerebro. Por ejemplo, son capaces de aprender de la experiencia, de generalizar de casos anteriores a nuevos. Esto hace que este tipo de tecnología sea tan relevante en nuestros tiempos y se esté aplicando en múltiples áreas.\n",
        "La principal ventaja de estas es que permiten resolver problemas muy diversos de manera relativamente sencilla, como, por ejemplo: problemas de predicción de valores, de clasificación de datos o de imágenes.\n",
        "\n",
        "#**Underfitting & Overfitting:**\n",
        "Para poder interpretar nuestros resultados de manera satisfactoria hace falta conocer los conceptos de undefitting y overfitting que se pueden entender como las principales causas por la cuales se pueden llagar a obtener malos resultados en nuestros modelos de Machine Learning.\n",
        "Si nuestros datos de entrenamiento son muy pocos nuestra maquina no será capaz de generalizar el conocimiento y estará incurriendo en underfitting. Por lo tanto, el algoritmo no será capaz de darnos un resultado bueno por la falta de datos para hacer solido su conocimiento.\n",
        "El overfitting es el riesgo que se corre al momento de que nuestro modelo se centra en memorizar particularidades concretas de nuestros datos de entrenamiento en lugar de encontrar una regla predictiva general.\n",
        "PyTorch\n",
        "\n",
        "#**PyTorch:** \n",
        "es un framework para machine learning de código abierto implementado por Meta. Este framework tiene varios módulos interesantes para el desarrollo de redes neuronales. PyTorch nos proporciona características de alto nivel como lo es la computación de tensores (Numpy) con una aceleración fuerte a través de unidades de procesamiento gráfico (GPU).\n"
      ],
      "metadata": {
        "id": "E8r4C9H26UTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Objetivos**\n",
        "**Objetivo general:**\n",
        "Aplicar los conocimientos obtenidos con el fin de crear un modelo predicitivo con el data set obtenido de precipitaciones en el Seattle-Tacoma International Airport la ciudad de Seattle.\n",
        "\n",
        " **Objetivos específicos:** Saber interpretar nuestros resultados y poder dar una conclusion sobre si nuestro modelo incurrimo o no en un caso de overfitting o underfitting."
      ],
      "metadata": {
        "id": "Tcx3QvQN6hWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Materiales y métodos**\n",
        "\n",
        "## *Materiales*\n",
        "\n",
        "Describir este conjunto de datos [[1]](https://www.kaggle.com/code/fatmakursun/rain-forecasting-with-artificial-neural-network/data).\n",
        "\n",
        "Esta base de datos fue recolectada en el Seattle-Tacoma International Airport, la cual nos provee de 5 parametros como los son la fecha de observacion (DATE), la cantidad de lluvia en pulgadas (PRCP), la temperatura máxima del día de observación en grados Fahrenheit (TMAX), la temperatura mínima del día de observación en grados Fahrenheit (TMIN) y True si llovió en el día de observación o False en el caso de que no se hubiese observado lluvia (RAIN).\n",
        "\n",
        "Este dataset nos sirve para poder crear nuestro modelo de predicción gracias a toda esta información recopilada a lo largo de todos estos años.\n",
        "\n",
        "\n",
        "## *Métodos*\n",
        "\n",
        "1. Esquema de metodología\n",
        "2. Descripción de los métodos y su implementación en código en forma de narrativa."
      ],
      "metadata": {
        "id": "4rX1w4ZD6mPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Resultados**\n",
        "Nuestro modeló arrojó datos muy interesantes. Al usar una función sigmoide nos muestra que los datos se están perdiendo, pero, al utilizar un numero muy grande de épocas, vemos que mientras más aprende el modelo más grande se encuentra nuestra exactitud. Pero tenemos que tener en cuenta un dato muy importante, el porcentaje de días en que no cayó lluvia es mayor a los días que si lo fueron. \n",
        "Esto puede significar que, al momento de nosotros querer entrenar la red, puede haber una tendencia hacía que no va a llover, por lo tanto nuestro modelo actúa como nosotros predijimos. \n",
        "Otro dato para considerar es el porcentaje de precipitación en el día exacto, este dato se nos presentó de manera muy ideal, por lo que, con los ajustes necesarios nos puede dar una exactitud del 100%, cosa que al momento de analizar las demás columnas nos indica que algo puede estar pasando con dicho modelo.\n",
        "Los rangos de temperatura al momento de analizarlos en el histograma nos arrojaron resultados no normalizados, por lo cual, estos datos están sesgados y afectan de manera negativa en el entrenamiento.\n",
        "Utilizamos la función sigmoide debido a que los rangos de temperatura y los porcentajes varían de manera ascendente con respecto al tiempo y nos interesa ver valores discretos en puntos concretos del tiempo.\n",
        "Para utilizar la columna de si llovió o no ese día, utilizamos una condicional que nos permita reemplazar esos valores como valores binarios para que la función sigmoide fluya correctamente.\n",
        "Nuestro algoritmo de optimización fue el de Adam, que actualmente, requiere dos parámetros. El segundo argumento lr es la tasa de aprendizaje. Se trata de un compromiso entre la calidad de los parámetros que vamos a encontrar y la rapidez con la que llegaremos a ellos\n",
        "Durante el entrenamiento, mostramos a nuestro modelo los datos durante 1.000 veces. Cada vez medimos la pérdida, propagamos los errores a través de nuestro modelo y pedimos al optimizador que encuentre mejores parámetros.\n",
        "El método zero_grad() borra los gradientes acumulados, que el optimizador utiliza para encontrar mejores parámetros.\n",
        "Usar sólo la precisión no sería una buena manera de hacerlo. ¡Recordemos que nuestros datos no contienen en su mayoría ejemplos de lluvia! Otra forma de profundizar un poco más en el rendimiento de nuestro modelo es evaluar la precisión y el recuerdo de cada clase.\n"
      ],
      "metadata": {
        "id": "6s3y9-yUSCL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Discusión**\n",
        "\n",
        "Nuestro modelo llegó a ser overfitting, debido a que los datos que le mandamos fue la alta posibilidad que lloviera o no, esto produjo que la red se sobreentrenara de tal manera que empezó a tomar ruidos provenientes de las demás capas para “normalizar” los valores extremos de las otras columnas como temperatura mínima o maxima.\n"
      ],
      "metadata": {
        "id": "AEt8aII8SPu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Conclusiones**\n",
        "En esta práctica se realizó una red neuronal para predecir si lloverá el siguiente día o no. El resultado esperado no precisáramos de que nos arrojara una salida extremadamente precisa, sin embargo, buscábamos analizar el comportamiento de las funciones de activaciones y de las capas de la red en sí. Al momento de analizar y preprocesar el conjunto de datos nos dimos cuenta de que el conjunto estaba sesgado y por lo tanto, algunos datos no eran tan congruentes, por ejemplo el PRCP, que al momento de utilizarlo y que al momento en que la red aprendiera, nos daban picos altos de una precisión, cosa que puede ser deducible debido a que este dato nos dice con una gran exactitud si hay lluvia o no.\n",
        "Prescindimos para practicas futuras utilizar métodos estadísticos más profundos para limpiar los datos de manera exitosa y que podamos abarcar muchos más factores externos.\n"
      ],
      "metadata": {
        "id": "8Gb2ac0VSryX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Referencias**\n",
        "\n",
        "[1] Pb, V. (2020, February 18). Perceptron. Kaggle. Retrieved June 1, 2022, from https://www.kaggle.com/code/prashfio/perceptron/notebook\n",
        "\n",
        "Wang, S. C. (2003). Artificial neural network. In Interdisciplinary computing in java programming (pp. 81-100). Springer, Boston, MA.\n",
        "\n",
        "Cerezo Sánchez, S. (2020). Herramientas modernas en Redes Neuronales: la librería PyTorch (Bachelor's thesis).\n",
        "\n"
      ],
      "metadata": {
        "id": "cxRqAiW5sG_m"
      }
    }
  ]
}